{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec for sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Corpora import MovieReviewCorpus\n",
    "from Lexicon import SentimentLexicon\n",
    "from Statistics import SignTest\n",
    "from Classifiers import NaiveBayesText, SVMText, BoWFeatureType\n",
    "from Extensions import SVMDoc2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reload changes from other modules without having to restart kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get training data for doc2vec\n",
    "\n",
    "The training data is a collection of documents (list of lists of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Convert text to lower-case and strip punctuation/symbols from words\"\"\"\n",
    "    # clean_text = text.lower() # Optional, convert text to lower-case\n",
    "    clean_text = text.replace('<br />', ' ') # Replace <br /> tags with spaces\n",
    "    for char in ['.', '\"', ',', '(', ')', '!', '?', ';', ':']: # Pad punctuation with spaces on both sides\n",
    "        clean_text = clean_text.replace(char, ' ' + char + ' ')\n",
    "    # clean_text = clean_text.replace(\"'\", \" '\") # Optional, left-pad apostrophes with spaces\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this for testing the clean_text function\n",
    "# dataset = \"train\"\n",
    "# label = \"neg\"\n",
    "# f = os.listdir(f\"data/aclImdb/{dataset}/{label}\")[0]\n",
    "# text = open(f\"data/aclImdb/{dataset}/{label}/{f}\").read()\n",
    "# clean_text(text)#.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents_for_doc2vec():\n",
    "    documents = []\n",
    "    i = 0\n",
    "    for dataset in [\"train\", \"test\"]:\n",
    "        for label in [\"neg\", \"pos\", \"unsup\"]:\n",
    "            if dataset == \"test\" and label == \"unsup\": continue\n",
    "            files = os.listdir(f\"data/aclImdb/{dataset}/{label}\")\n",
    "            for file in files:\n",
    "                text = open(f\"data/aclImdb/{dataset}/{label}/{file}\").read()\n",
    "                text = clean_text(text)\n",
    "                documents.append(TaggedDocument(text.split(), [i]))\n",
    "                i += 1\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = get_documents_for_doc2vec()\n",
    "print(f\"We have {len(documents)} documents for training doc2vec models\")\n",
    "shortest_doc = np.argmin(np.array([len(d[0]) for d in documents]))\n",
    "print(f\"The shortest document looks like:\\n{documents[shortest_doc]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train various doc2vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_kwargs = dict(vector_size=100, epochs=20, min_count=2, sample=0, workers=8, negative=5, hs=0)\n",
    "model = Doc2Vec(documents, vector_size=100, window=10, dm=1, workers=8) # dm = 1 for PV-DM, 0 for PV-DBOW, dm_concat for both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compare SVM using doc2vec-features with Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyse the doc2vec approach\n",
    "\n",
    "Perhaps, compare the embeddings for \"This film sucks.\" and \"The movie is terrible!\", versus \"Great movie!\" and \"This film is brilliant\"."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbee541ec4efbfd295a700d5b5221527a3248196120936dbde7b8b54db516aa4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('mlmi13-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
